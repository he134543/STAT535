# Define function
get_discharge_data <- function(site_no, q_code, start, end) {
# Build the url link
url <- paste0('https://waterdata.usgs.gov/nwis/dv?cb_',
q_code,
'=on&format=html&site_no=',
site_no,
'&legacy=&re[…]module=sw&period=&begin_date=',
start,
'&end_date=',
end)
q_data <- readLines(url)
# Select lines which contains the data
table_pattern <- '<tr align="center"><td nowrap="nowrap">'
q_table <- str_subset(q_data, table_pattern)
# Extract dates and flow(ft3/s) from each line
dates = as.Date(unlist(str_match_all(q_table, "[0-9]*/[0-9]*/[0-9]*")), "%m/%d/%y")
flows = unlist(str_match_all(q_table, "<span>.*</span>"))
flows = as.numeric(str_replace_all(flows, "</?span>", ""))
# Put dates and flow together as a matrix
Q_df = data.frame(
Dates = dates,
Qobs = flows
)
return(Q_df)
}
q_df <- get_discharge_data(site_no, q_code, start, end)
library(ggplot2)
validate_q <- readNWISdv(siteNumber = site_no, parameterCd = q_code,
start, end)
# install.packages("dataRetrieval")
library(dataRetrieval)
suppressMessages(library(tidyverse))
library(dataRetrieval)
library(dplyr)
library(ggplot2)
update()
updateR()
install.packages("updater")
# install.packages("dataRetrieval")
library(dataRetrieval)
suppressMessages(library(tidyverse))
library(dataRetrieval)
library(dplyr)
library(ggplot2)
updater
sessioninfo()
setwd("C:/Users/xinch/OneDrive - University of Massachusetts/2022Fall_Courses/Statistical_computing/FP/STAT535")
# install.packages("dataRetrieval")
library(dataRetrieval)
suppressMessages(library(tidyverse))
library(dataRetrieval)
library(dplyr)
library(ggplot2)
# Specify the inputs: gauge number, q_code is fixed, start date and end date
site_no <- '08324000'
q_code <- '00060'
start <- '2000-01-01'
end <- '2020-12-31'
# Define function
get_discharge_data <- function(site_no, q_code, start, end) {
# Build the url link
url <- paste0('https://waterdata.usgs.gov/nwis/dv?cb_',
q_code,
'=on&format=html&site_no=',
site_no,
'&legacy=&re[…]module=sw&period=&begin_date=',
start,
'&end_date=',
end)
q_data <- readLines(url)
# Select lines which contains the data
table_pattern <- '<tr align="center"><td nowrap="nowrap">'
q_table <- str_subset(q_data, table_pattern)
# Extract dates and flow(ft3/s) from each line
dates = as.Date(unlist(str_match_all(q_table, "[0-9]*/[0-9]*/[0-9]*")), "%m/%d/%y")
flows = unlist(str_match_all(q_table, "<span>.*</span>"))
flows = as.numeric(str_replace_all(flows, "</?span>", ""))
# Put dates and flow together as a matrix
Q_df = data.frame(
Dates = dates,
Qobs = flows
)
return(Q_df)
}
q_df <- get_discharge_data(site_no, q_code, start, end)
validate_q <- readNWISdv(siteNumber = site_no, parameterCd = q_code,
start, end)
validate_q
validate_q <- readNWISdv(siteNumber = site_no, parameterCd = q_code,
start, end)
ggplot()
+ geom_line(data = q_df, aes(Date, Q_obs))
validate_q <- readNWISdv(siteNumber = site_no, parameterCd = q_code,
start, end)
ggplot() +
geom_line(data = q_df, aes(Date, Q_obs)) +
geom_line(data = q_df, aes(Date, X_00060_00003))
validate_q
validate_q <- readNWISdv(siteNumber = site_no, parameterCd = q_code,
start, end)
ggplot() +
geom_line(data = q_df, aes(Dates, Q_obs)) +
geom_line(data = q_df, aes(Date, X_00060_00003))
# Specify the inputs: gauge number, q_code is fixed, start date and end date
site_no <- '08324000'
q_code <- '00060'
start <- '2000-01-01'
end <- '2020-12-31'
# Define function
get_discharge_data <- function(site_no, q_code, start, end) {
# Build the url link
url <- paste0('https://waterdata.usgs.gov/nwis/dv?cb_',
q_code,
'=on&format=html&site_no=',
site_no,
'&legacy=&re[…]module=sw&period=&begin_date=',
start,
'&end_date=',
end)
q_data <- readLines(url)
# Select lines which contains the data
table_pattern <- '<tr align="center"><td nowrap="nowrap">'
q_table <- str_subset(q_data, table_pattern)
# Extract dates and flow(ft3/s) from each line
dates = as.Date(unlist(str_match_all(q_table, "[0-9]*/[0-9]*/[0-9]*")), "%m/%d/%y")
flows = unlist(str_match_all(q_table, "<span>.*</span>"))
flows = as.numeric(str_replace_all(flows, "</?span>", ""))
# Put dates and flow together as a matrix
Q_df = data.frame(
Date = dates,
Qobs = flows
)
return(Q_df)
}
q_df <- get_discharge_data(site_no, q_code, start, end)
validate_q <- readNWISdv(siteNumber = site_no, parameterCd = q_code,
start, end)
ggplot() +
geom_line(data = q_df, aes(Dates, Qobs)) +
geom_line(data = q_df, aes(Date, X_00060_00003))
validate_q <- readNWISdv(siteNumber = site_no, parameterCd = q_code,
start, end)
ggplot() +
geom_line(data = q_df, aes(Date, Qobs)) +
geom_line(data = q_df, aes(Date, X_00060_00003))
validate_q <- readNWISdv(siteNumber = site_no, parameterCd = q_code,
start, end)
ggplot() +
geom_line(data = q_df, aes(x = Date, y = Qobs), color = 'black') +
geom_line(data = validate_q, aes(x = Date, y = X_00060_00003), color = 'red')
q_df$Qobs - validate_q$X_00060_00003
validate_q <- readNWISdv(siteNumber = site_no, parameterCd = q_code,
start, end)
ggplot() +
geom_line(data = q_df, aes(x = Date, y = Qobs), color = 'black') +
#geom_line(data = validate_q, aes(x = Date, y = X_00060_00003), color = 'red')
validate_q <- readNWISdv(siteNumber = site_no, parameterCd = q_code,
start, end)
ggplot() +
geom_line(data = q_df, aes(x = Date, y = Qobs), color = 'black')
#geom_line(data = validate_q, aes(x = Date, y = X_00060_00003), color = 'red')
# Specify the inputs: gauge number, q_code is fixed, start date and end date
site_no <- '08324000'
q_code <- '00060'
start <- '2000-01-01'
end <- '2020-12-31'
# Define function
get_discharge_data <- function(site_no, q_code, start, end) {
# Build the url link
url <- paste0('https://waterdata.usgs.gov/nwis/dv?cb_',
q_code,
'=on&format=html&site_no=',
site_no,
'&legacy=&re[…]module=sw&period=&begin_date=',
start,
'&end_date=',
end)
q_data <- readLines(url)
# Select lines which contains the data
table_pattern <- '<tr align="center"><td nowrap="nowrap">'
q_table <- str_subset(q_data, table_pattern)
# Extract dates and flow(ft3/s) from each line
dates = as.Date(unlist(str_match_all(q_table, "[0-9]*/[0-9]*/[0-9]*")), "%m/%d/%y")
flows = unlist(str_match_all(q_table, "<span>.*</span>"))
flows = as.numeric(str_replace_all(flows, "</?span>", ""))
# Put dates and flow together as a matrix
Q_df = data.frame(
Date = dates,
Qobs = flows
)
return(Q_df)
}
q_df <- get_discharge_data(site_no, q_code, start, end)
validate_q <- readNWISdv(siteNumber = site_no, parameterCd = q_code,
start, end)
ggplot() +
geom_line(data = q_df, aes(x = Date, y = Qobs), color = 'black')
+geom_line(data = validate_q, aes(x = Date, y = X_00060_00003), color = 'red')
q_df
# Build the url link
url <- paste0('https://waterdata.usgs.gov/nwis/dv?cb_',
q_code,
'=on&format=html&site_no=',
site_no,
'&legacy=&re[…]module=sw&period=&begin_date=',
start,
'&end_date=',
end)
q_data <- readLines(url)
# Select lines which contains the data
table_pattern <- '<tr align="center"><td nowrap="nowrap">'
q_table <- str_subset(q_data, table_pattern)
# Extract dates and flow(ft3/s) from each line
dates = as.Date(unlist(str_match_all(q_table, "[0-9]*/[0-9]*/[0-9]*")), "%m/%d/%y")
dates
unlist(str_match_all(q_table, "[0-9]*/[0-9]*/[0-9]*"))
as.Date(unlist(str_match_all(q_table, "[0-9]*/[0-9]*/[0-9]*")), "%m/%d/%Y")
# Specify the inputs: gauge number, q_code is fixed, start date and end date
site_no <- '08324000'
q_code <- '00060'
start <- '2000-01-01'
end <- '2020-12-31'
# Define function
get_discharge_data <- function(site_no, q_code, start, end) {
# Build the url link
url <- paste0('https://waterdata.usgs.gov/nwis/dv?cb_',
q_code,
'=on&format=html&site_no=',
site_no,
'&legacy=&re[…]module=sw&period=&begin_date=',
start,
'&end_date=',
end)
q_data <- readLines(url)
# Select lines which contains the data
table_pattern <- '<tr align="center"><td nowrap="nowrap">'
q_table <- str_subset(q_data, table_pattern)
# Extract dates and flow(ft3/s) from each line
dates = as.Date(unlist(str_match_all(q_table, "[0-9]*/[0-9]*/[0-9]*")), "%m/%d/%Y")
flows = unlist(str_match_all(q_table, "<span>.*</span>"))
flows = as.numeric(str_replace_all(flows, "</?span>", ""))
# Put dates and flow together as a matrix
Q_df = data.frame(
Date = dates,
Qobs = flows
)
return(Q_df)
}
q_df <- get_discharge_data(site_no, q_code, start, end)
validate_q <- readNWISdv(siteNumber = site_no, parameterCd = q_code,
start, end)
ggplot() +
geom_line(data = q_df, aes(x = Date, y = Qobs), color = 'black')
+geom_line(data = validate_q, aes(x = Date, y = X_00060_00003), color = 'red')
validate_q <- readNWISdv(siteNumber = site_no, parameterCd = q_code,
start, end)
ggplot()
+ geom_line(data = q_df, aes(x = Date, y = Qobs), color = 'black')
validate_q <- readNWISdv(siteNumber = site_no, parameterCd = q_code,
start, end)
ggplot() +
geom_line(data = q_df, aes(x = Date, y = Qobs), color = 'black') +
geom_line(data = validate_q, aes(x = Date, y = X_00060_00003), color = 'red') +
validate_q <- readNWISdv(siteNumber = site_no, parameterCd = q_code,
start, end)
ggplot() +
geom_line(data = q_df, aes(x = Date, y = Qobs), color = 'black') +
geom_line(data = validate_q, aes(x = Date, y = X_00060_00003), color = 'red')
# Get authentic streamflow data using the package
validate_q <- readNWISdv(siteNumber = site_no, parameterCd = q_code,
start, end)
# Calculate the error between scraped data and the true data
scrape_error = q_df$Qobs - validate_q$X_00060_00003
ggplot() +
geom_histogram(scrape_error)
scrape_error
# Get authentic streamflow data using the package
validate_q <- readNWISdv(siteNumber = site_no, parameterCd = q_code,
start, end)
# Calculate the error between scraped data and the true data
scrape_error = q_df$Qobs - validate_q$X_00060_00003
hist(scrape_error)
# Get authentic streamflow data using the package
validate_q <- readNWISdv(siteNumber = site_no, parameterCd = q_code,
start, end)
# Calculate the error between scraped data and the true data
scrape_error = q_df$Qobs - validate_q$X_00060_00003
plot(scrape_error)
# Get authentic streamflow data using the package
validate_q <- readNWISdv(siteNumber = site_no, parameterCd = q_code,
start, end)
# Calculate the error between scraped data and the true data
scrape_error = q_df$Qobs - validate_q$X_00060_00003
plot(q_df$Date, scrape_error)
# Specify the inputs: gauge number, q_code is fixed, start date and end date
site_no <- '08324000'
q_code <- '00060'
start <- '2000-01-01'
end <- '2020-12-31'
# Use the function we have to scrape
q_df <- get_discharge_data(site_no, q_code, start, end)
# Get authentic streamflow data using the package
validate_q <- readNWISdv(siteNumber = site_no, parameterCd = q_code,
start, end)
# Calculate the error between scraped data and the true data
scrape_error = q_df$Qobs - validate_q$X_00060_00003
plot(q_df$Date, scrape_error)
print(1,2)
# Load the site list
site_df <- read.csv("gauges_Mass.txt", header = FALSE)
site_list <- site_df[,1]
#
for (site_no in site_list){
site_no <- paste0('0',as.character(site_no))
print(paste('Gauge ',site_no,' Scraping start'))
q_df <- try({
get_discharge_data(site_no, q_code, start, end)
q_df.save(paste0("streamflows/", site_no,".csv"))
}, silent = TRUE)
print(paste('Gauge ',site_no,' Done'))
break
}
pwd
# Load the site list
site_df <- read.csv("gauges_Mass.txt", header = FALSE)
site_list <- site_df[,1]
#
for (site_no in site_list){
site_no <- paste0('0',as.character(site_no))
print(paste('Gauge ',site_no,' Scraping start'))
try({
q_df <- get_discharge_data(site_no, q_code, start, end)
q_df.save(paste0("streamflows/", site_no,".csv"))
}, silent = TRUE)
print(paste('Gauge ',site_no,' Done'))
break
}
# Load the site list
site_df <- read.csv("gauges_Mass.txt", header = FALSE)
site_list <- site_df[,1]
#
for (site_no in site_list){
site_no <- paste0('0',as.character(site_no))
print(paste('Gauge ',site_no,' Scraping start'))
q_df <- try({
q_df <- get_discharge_data(site_no, q_code, start, end)
}, silent = TRUE)
q_df.save(paste0("streamflows/", site_no,".csv"))
print(paste('Gauge ',site_no,' Done'))
break
}
# Load the site list
site_df <- read.csv("gauges_Mass.txt", header = FALSE)
site_list <- site_df[,1]
#
for (site_no in site_list){
site_no <- paste0('0',as.character(site_no))
print(paste('Gauge ',site_no,' Scraping start'))
q_df <- try({
q_df <- get_discharge_data(site_no, q_code, start, end)
}, silent = TRUE)
try({
write.csv(paste0("streamflows/", site_no,".csv"))
}, silent = TRUE)
print(paste('Gauge ',site_no,' Done'))
break
}
# Load the site list
site_df <- read.csv("gauges_Mass.txt", header = FALSE)
site_list <- site_df[,1]
#
for (site_no in site_list){
site_no <- paste0('0',as.character(site_no))
print(paste('Gauge ',site_no,' Scraping start'))
q_df <- try({
q_df <- get_discharge_data(site_no, q_code, start, end)
}, silent = TRUE)
try({
write.csv(q_df, paste0("streamflows/", site_no,".csv"))
}, silent = TRUE)
print(paste('Gauge ',site_no,' Done'))
break
}
# Load the site list
site_df <- read.csv("gauges_Mass.txt", header = FALSE)
site_list <- site_df[,1]
#
for (site_no in site_list){
site_no <- paste0('0',as.character(site_no))
print(paste('Gauge ',site_no,' Scraping start'))
q_df <- try({
q_df <- get_discharge_data(site_no, q_code, start, end)
}, silent = TRUE)
try({
write.csv(q_df, paste0("streamflows/", site_no,".csv"), row.names = FALSE)
}, silent = TRUE)
print(paste('Gauge ',site_no,' Done'))
break
}
# Load the site list
site_df <- read.csv("gauges_Mass.txt", header = FALSE)
site_list <- site_df[,1]
#
for (site_no in site_list){
site_no <- paste0('0',as.character(site_no))
print(paste('Gauge ',site_no,' Scraping start'))
q_df <- try({
q_df <- get_discharge_data(site_no, q_code, start, end)
}, silent = TRUE)
try({
write.csv(q_df, paste0("streamflows/", site_no,".csv"), row.names = FALSE)
}, silent = TRUE)
print(paste('Gauge ',site_no,' Done'))
}
?read.csv
read.csv("gauges_Mass.txt", header = FALSE, colClasses = character)
site_df
readlines("gauges_Mass.txt")
readline("gauges_Mass.txt")
readLines("gauges_Mass.txt")
# Load the site list
site_list <- readLines("gauges_Mass.txt")
# create an empty list to save drainage area
da_area <- numeric()#
for (site_no in site_list){
da_area = c(da_area, get_drainage_area(site_no))
}
get_drainage_area = function(site_no){
# Scrape the drainage area
url2 <- paste0('https://waterdata.usgs.gov/nwis/inventory/?site_no=',
site_no,
'&agency_cd=USGS')
d_data <- readLines(url2)
d_pattern <- "^.*Drainage area"
d_line <- str_subset(d_data,d_pattern)
darea <- unique(unlist(str_extract_all(d_line, "[0-9]*\\.?[0-9]*")))[2]
darea <- as.numeric(darea)
return(darea)
}
# Load the site list
site_list <- readLines("gauges_Mass.txt")
# create an empty list to save drainage area
da_area <- numeric()#
for (site_no in site_list){
da_area = c(da_area, get_drainage_area(site_no))
}
da_area
writeLines(da_area)
# Save the drainge area
try({
write.csv(data.frame(
site_no = site_list
drainage_area = da_area
# Save the drainge area
try({
write.csv(data.frame(
site_no = site_list,
drainage_area = da_area
), "drainage_area.csv", row.names = FALSE)
})
numeric(100)
site_list <- readLines("gauges_Mass.txt")
# create an empty list to save drainage area
da_area <- numeric(length(site_list))#
counter = 1
for (site_no in site_list){
da_area[counter] = try({
c(da_area, get_drainage_area(site_no))
})
counter = counter + 1
print(site_no)
}
da_area
counter = 1
for (site_no in site_list){
da_area[counter] = try({
get_drainage_area(site_no)
})
counter = counter + 1
print(site_no)
}
# Load the site list
site_list <- readLines("gauges_Mass.txt")
# create an empty list to save drainage area
da_area <- vector(length(site_list))#
get_drainage_area("01100870")
counter = 1
for (site_no in site_list){
try({
da_area[counter] = get_drainage_area(site_no)
})
counter = counter + 1
print(site_no)
}
# Save the drainge area
write.csv(data.frame(
site_no = site_list,
drainage_area = da_area
), "drainage_area.csv", row.names = FALSE)
write.csv(data.frame(
site_no = site_list,
drainage_area = da_area
), "drainage_area.txt", row.names = FALSE)
read.csv("drainage_area.txt")
read.csv("drainage_area.txt", colClasses = c(site_no = character))
?read.csv
read.csv("drainage_area.txt", colClasses = c("character", "numeric"))
# Load the site list
site_df <- readLines("gauges_Mass.txt", header = FALSE)
# Note: not all the site have a validate
read.csv("drainage_area.txt", colClasses = c("character", "numeric"))
